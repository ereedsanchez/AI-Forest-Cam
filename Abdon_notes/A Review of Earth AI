Abdon Vizcarrondo
October 2023	
A Review of Earth AI
This paper highlights the exponential growth of geolocated data from around the world from sensors and the need for integrating artificial intelligence into geosciences. It criticizes manual data handling and unrealistic modeling assumptions. The paper introduces "Earth Artificial Intelligence" (Earth AI), a system designed to monitor nature, adapt society to environmental changes, guide policymaking, and mitigate geohazards. Earth AI is seen as a potential solution to global challenges like overpopulation, food security, and climate change. Outlined sections discuss current AI techniques, applications in geosciences, Earth AI workflows, tools, challenges, and opportunities.

AI techniques relevant to geosciences that are currently being utilized, which afford geoscientists the ability to extract valuable insights and make informed decisions in their field. 

* Knowledge-based systems rely on sets of rules for data analysis, offering stability and reliability in decision-making.Probabilistic machine learning addresses uncertainty in data and is commonly employed to enhance prediction accuracy by using probability theory.
* Unsupervised learning, in contrast to supervised learning with labeled data, identifies hidden patterns in datasets, frequently used in clustering analysis.
* Supervised learning is the approach currently prevalent today. Creating connections between input and output data, with subdivisions into regression and classification, and various algorithms to enhance accuracy.
* Deep learning involves neural networks with numerous layers, particularly deep convolutional neural networks (DCNN) for feature extraction. Although excelling in performance, it requires substantial high-quality labeled data.
* Reinforcement learning is commonly employed to determine the optimal path to maximize rewards in goal-driven situations, particularly suitable for scenarios where comprehensive and correct data might be elusive.
* 
AI has gained prominence in various fields due to its ability to address complex challenges and enhance understanding.

In the geosphere, AI is employed to study and predict geohazards such as earthquakes, volcanic eruptions, and landslides. Machine learning (ML) techniques like feedforward and recurrent neural networks are used to predict earthquake characteristics, while AI helps in differentiating seismic volcanic tremors and forecasting volcanic eruptions. Landslide studies involve risk estimation and the automation of landslide identification using various machine learning approaches.

Within the hydrosphere, AI methods aid in rainfall forecasting, surface water monitoring, and groundwater management. Rainfall forecasting is achieved through combinations of recurrent neural networks and support vector machines, and AI assists in predicting streamflow, water quality, and water level. Groundwater management maps, risk assessments for nitrate contamination, and groundwater level predictions are also enhanced using AI and ML techniques.

In the atmosphere, AI is instrumental in hurricane path prediction and damage assessment, meteorological drought forecasting, wildfire detection, and predicting the occurrence of dust storms. AI aids in recognizing patterns in seismic activities and provides critical information on air pollution, especially for ozone and fine particle predictions. Additionally, AI plays an essential role in studying the biosphere, involving plant, animal, and microorganism research. AI contributes to identifying and classifying plants, recognizing wildlife behavior, and forecasting microorganism evolution and activities.

In the cryosphere, AI aids in sea ice mapping, snow research, and identifying changes in frozen areas. It offers a means to monitor sea ice thickness and quality and helps differentiate snow from cloud cover. In oceanography, AI is used to map and identify ocean features such as eddies, roughness, and surface temperature. It addresses data gaps in satellite observations and contributes to the three-dimensional understanding of ocean circulation, promising applications in climate models. AI is expected to play an essential role in managing the ever-increasing abundance of oceanographic data.
The workflow in Earth sciences, especially for supervised machine learning research, involves data preparation, model building, training, testing, validation, and sensitivity analysis. 

Data preparation is a crucial step, and it involves dealing with time series data, various data formats, coordinate systems, and metadata standardization issues. 

Model building requires a deep understanding of the problem and ML models, with an emphasis on finding the right model architecture through experimentation. The training, testing, and validation phases involve splitting the data into appropriate sets and using cross-validation techniques to ensure model accuracy and performance. 

Sensitivity analysis is used to quantify the uncertainties and possible margins of error present in ML and to understand the importance of input variables. It helps professionals gain more control over their models and is critical for real-world applications.

In the realm of Earth science and artificial intelligence, powerful computing tools and services are essential due to the big data nature of the field and the complexity of AI algorithms. 

Various computing devices are employed, with Graphics Processing Units (GPUs) being prominent due to their superior performance in tasks like convolution and matrix operations. Although not currently available on the market quantum computing and edge computing are emerging areas of exploration, offering new ways to tackle computationally intensive tasks and improve AI's resilience. Researchers can build their own workstations utilizing clusters of GPUs, while institutions often opt for pre-built servers. 

Public cyberinfrastructure like Google Earth Engine and Amazon's SageMaker, as well as interactive coding environments like Colab, have revolutionized Earth scientific research by providing access to large datasets and advanced AI tools. 

Linux-based operating systems, particularly Ubuntu, seem to to be the recommended linux distribution for their long term support (LTS), flexibility and compatibility with AI tools. 

Python remains the dominant language in AI, benefiting from a rich library ecosystem that encompasses deep learning, machine learning, artificial intelligence, data manipulation, parallel computing, and visualization tools, all contributing to significant scientific breakthroughs that bridge Earth science with ever emerging AI techniques.

In the context of model development, there exists challenges in selecting and customizing models for training datasets, including the demand for AutoML out of the many offered, as it does not require expert knowledge or manual tuning. This assist in simplifying the process and bridge the gap between AI experts and non-experts. It emphasizes the importance of considering various metrics beyond accuracy when evaluating model performance. (Candidate off-the-shelf models include single models such as Neural Network, SVM, and Decision Tree, as well as ensemble models like RF, XGBoost, and most DL models.)

Data preparation is identified as a major focus area in Earth AI, with crowd-sourcing and standardization of training datasets being essential. The lack of labeled and curated data is seen as a hindrance as costs are exorbitantly high as labeling is usually done by in-house labor, and the current developments of standardized benchmark datasets, to where no international standards exists yet, is suggested to alleviate data curation burdens.

Tuning AI Models with a focus on the challenges of hyperparameter tuning is crucial to minimize the cost function and the need for methods that can efficiently handle gradient-based optimization issues and the risk of overfitting.

Parallel computing is seen as valuable in Earth AI due to the increasing size of Earth data and the complexity of AI models. Advances in ML models, especially DL models, are more and more complex to achieve prediction accuracy. The need for these unified systems and methods that support parallel learning, particularly for spatiotemporal data, typifying Earth system datasets would be beneficial, as partitioning spatiotemporal data would break their spatial/temporal correlation and dependence.
Explainable AI (XAI) is identified as essential, especially in complex models, to enhance understanding and trust. This process answers questions about the model, such as what features are the most important and why some features are more responsible for driving decisions than others. Although they may be useful for discovering artifacts that create errors through focusing on higher dimensional RGB images, limitations exist. Current XAI methods cannot decipher the problems in the training dataset.
Generalization challenges are outlined, emphasizing the need to address problems related to the dataset's size, diversity, and distribution. Strategies like cross-validation to ensure no coincidental training bias is in place. Regularization is a system in place to encourage the learning algorithm to generalize better. Focusing on minimizing the impacts of noise samples that don't echo the characteristics of the dataset, but instead produce random inaccuracies and coincidences.
Integration with physics-based models is presented as a way to enhance modeling accuracy and efficiency, either by incorporating AI within traditional frameworks or by introducing physics laws into data-driven models.

Provenance, reproducibility, replicability, and reusability are identified as important concerns. Where did all components of the training data originate, and what alterations have been made to the data before the findings were reported? Can an independent party duplicate the precise AI workflow and results that have been reported, using the same data set and algorithms? Can an independent party run similar evaluations on similar data and come to the same conclusions? Can an independent party run similar analyses on data sets and deduce similar conclusions? How easily can the trained AI models be applied to new data or other new situations?

Taking AI ethics and concerns into consideration highlights the need for more open datasets and unbiased algorithms to ensure fairness and transparency. Collaboration with social scientists, ethicists, and philosophers is encouraged .The potential of Earth AI is emphasized on issues that forecast Earth's future, mitigate natural hazards, and protect the environment. However, it acknowledges that Earth AI's capabilities have limitations, and there is a concern about its potential to miscalculate situations, potentially leading to unequal impacts on regions or groups. While Earth AI is intelligent, it is not a legal entity, yet its decisions can have significant societal impacts. This raises ethical concerns that have been the focus of extensive research on AI's operational effects, including issues related to cultural bias and algorithmic inequality. We must anticipating the introduction of regulations and laws addressing Earth AI ethics. To ensure ethical AI in Earth and environmental sciences, there are several approaches, including promoting more open datasets and unbiased algorithms. Collaboration between engineers, social scientists, ethicists, and philosophers is recommended to develop ethical guidelines for AI projects. Furthermore, it emphasizes the importance of transparently communicating AI applications' impacts on broader communities, especially in cases where AI can affect representations of Indigenous land. The exists a need for operational support and maintenance of AI services, suggesting that DevOps practices and internal capacity building can help overcome the challenges of deploying and sustaining AI operations.

Highlighted in this research is the latest AI research in geosciences, emphasizing the need to keep up with growing data. Earth AI is still in its early stages but offers great potential to address various challenges, benefiting society and the environment for a more sustainable planet.
